import json
import time
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from bs4 import BeautifulSoup
import warnings
import os
import dotenv
import os
from src.preprocessing.crawling.BankLink import BankLink

warnings.filterwarnings('ignore')

class IBKFullCrawler:
    def __init__(self):
        self.base_url = BankLink.IBK_BANK_LINK.value
        
        # ì ê¸ˆ ìƒí’ˆ (ëª©ëˆëª¨ìœ¼ê¸°) - 3í˜ì´ì§€, 28ê°œ ìƒí’ˆ
        self.savings_url = BankLink.IBK_BANK_SAVINGS_LINK.value
        self.savings_pages = 3
        
        # ì˜ˆê¸ˆ ìƒí’ˆ (ëª©ëˆêµ´ë¦¬ê¸°) - 2í˜ì´ì§€, 17ê°œ ìƒí’ˆ
        self.deposits_url = BankLink.IBK_BANK_DEPOSIT_LINK.value
        self.deposits_pages = 2
        
        self.driver = None
        self.all_products = []
        
    def setup_driver(self):
        """WebDriver ì„¤ì •"""
        options = Options()
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        # ì•ˆì •ì„±ì„ ìœ„í•´ í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ í™œì„±í™”
        options.add_argument('--headless')
        
        try:
            possible_paths = [
                '/opt/homebrew/bin/chromedriver',
                '/usr/local/bin/chromedriver',
            ]
            
            driver_created = False
            for path in possible_paths:
                try:
                    if os.path.exists(path):
                        service = Service(path)
                        self.driver = webdriver.Chrome(service=service, options=options)
                        driver_created = True
                        break
                except:
                    continue
            
            if not driver_created:
                self.driver = webdriver.Chrome(options=options)
            
            self.driver.implicitly_wait(5)
            
            print("âœ… WebDriver ì„¤ì • ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ WebDriver ì„¤ì • ì‹¤íŒ¨: {e}")
            return False

    def crawl_all_products(self):
        """ì ê¸ˆê³¼ ì˜ˆê¸ˆ ìƒí’ˆ ëª¨ë‘ í¬ë¡¤ë§"""
        print("ğŸš€ === ibk ì ê¸ˆ/ì˜ˆê¸ˆ ì „ì²´ í¬ë¡¤ëŸ¬ (ê¸°ê°„ë³„ ê¸ˆë¦¬ í¬í•¨) ===")
        print("ğŸ“‹ ëª©ëˆëª¨ìœ¼ê¸°(ì ê¸ˆ) 28ê°œ + ëª©ëˆêµ´ë¦¬ê¸°(ì˜ˆê¸ˆ) 17ê°œ = ì´ 45ê°œ")
        print("ğŸ¯ ìˆ˜ì§‘ ì •ë³´: ê°€ì…ê¸ˆì•¡, ê°€ì…ëŒ€ìƒ, ê°€ì…ë°©ë²•, ê°€ì…ê¸°ê°„, ê¸ˆë¦¬, ìš°ëŒ€ì¡°ê±´, ê¸°ê°„ë³„ê¸ˆë¦¬ ë“±\n")
        
        if not self.setup_driver():
            return {}
        
        try:
            results = {
                'crawl_info': {
                    'crawl_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'target_pages': {
                        'savings': self.savings_pages,
                        'deposits': self.deposits_pages
                    },
                    'total_expected': 45  # 28 + 17
                },
                'products': []  # í†µí•©ëœ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸
            }
            
            # 1. ì ê¸ˆ ìƒí’ˆ í¬ë¡¤ë§ (ëª©ëˆëª¨ìœ¼ê¸°)
            print("ğŸ’° === ì ê¸ˆ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘ ===")
            savings_products = self.crawl_product_category(
                category_name="ì ê¸ˆ",
                base_url=self.savings_url,
                max_pages=self.savings_pages
            )
            
            # 2. ì˜ˆê¸ˆ ìƒí’ˆ í¬ë¡¤ë§ (ëª©ëˆêµ´ë¦¬ê¸°)
            print("\nğŸ¦ === ì˜ˆê¸ˆ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘ ===")
            deposits_products = self.crawl_product_category(
                category_name="ì˜ˆê¸ˆ",
                base_url=self.deposits_url,
                max_pages=self.deposits_pages
            )
            
            # 3. í†µí•© ê²°ê³¼ êµ¬ì„±
            all_products = savings_products + deposits_products
            results['products'] = all_products
            results['crawl_info']['actual_collected'] = len(all_products)
            results['crawl_info']['savings_count'] = len(savings_products)
            results['crawl_info']['deposits_count'] = len(deposits_products)
            
            print(f"\nğŸ‰ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ!")
            print(f"ğŸ“Š ì ê¸ˆ ìƒí’ˆ: {len(savings_products)}ê°œ")
            print(f"ğŸ“Š ì˜ˆê¸ˆ ìƒí’ˆ: {len(deposits_products)}ê°œ")
            print(f"ğŸ“Š ì´í•©: {len(all_products)}ê°œ")
            
            return results
            
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
        finally:
            if self.driver:
                self.driver.quit()

    def crawl_product_category(self, category_name, base_url, max_pages):
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  í˜ì´ì§€ í¬ë¡¤ë§"""
        category_products = []
        seen_products = set()
        
        for page_num in range(1, max_pages + 1):
            print(f"\n{'='*60}")
            print(f"ğŸ“„ {category_name} í˜ì´ì§€ {page_num}/{max_pages}")
            print(f"{'='*60}")
            
            # í˜ì´ì§€ ì´ë™
            success = self.navigate_to_page(category_name, base_url, page_num)
            
            if not success:
                print(f"âŒ í˜ì´ì§€ {page_num} ì´ë™ ì‹¤íŒ¨")
                continue
            
            # í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°
            time.sleep(3)
            
            try:
                # ìƒí’ˆ ëª©ë¡ ì¶”ì¶œ
                page_products = self.extract_products_from_current_page()
                
                if not page_products:
                    print(f"âŒ í˜ì´ì§€ {page_num}ì—ì„œ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    continue
                
                print(f"ğŸ“¦ í˜ì´ì§€ {page_num}ì—ì„œ {len(page_products)}ê°œ ìƒí’ˆ ë°œê²¬")
                
                # ì¤‘ë³µ ìƒí’ˆ í•„í„°ë§
                new_products = []
                for product in page_products:
                    product_key = product['name']
                    if product_key not in seen_products:
                        seen_products.add(product_key)
                        new_products.append(product)
                    else:
                        print(f"    âš ï¸ ì¤‘ë³µ ìƒí’ˆ ìŠ¤í‚µ: {product_key}")
                
                if not new_products:
                    print(f"âš ï¸ í˜ì´ì§€ {page_num}ì— ìƒˆë¡œìš´ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤!")
                
                # ê° ìƒí’ˆì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
                for i, product in enumerate(new_products, 1):
                    global_index = len(category_products) + 1
                    print(f"\n[{category_name} {global_index}] {product['name']}")
                    
                    # ìƒí’ˆ ê°„ ëŒ€ê¸° (ì²« ë²ˆì§¸ ì œì™¸)
                    if i > 1:
                        print(f"    â³ ìƒí’ˆ ê°„ ëŒ€ê¸°...")
                        time.sleep(2)
                    
                    # ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
                    detail_info = self.get_product_detail(product, category_name)
                    
                    if detail_info:
                        category_products.append(detail_info)
                        print(f"    âœ… ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
                        
                        # ê¸°ê°„ë³„ ê¸ˆë¦¬ ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
                        if detail_info.get('ê¸°ê°„ë³„ê¸ˆë¦¬'):
                            print(f"    ğŸ“Š ê¸°ê°„ë³„ê¸ˆë¦¬ {len(detail_info['ê¸°ê°„ë³„ê¸ˆë¦¬'])}ê°œ ìˆ˜ì§‘")
                        else:
                            print(f"    ğŸ“‹ ê¸°ê°„ë³„ê¸ˆë¦¬: ì—†ìŒ")
                            
                        # ìš°ëŒ€ì¡°ê±´ ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
                        if detail_info.get('ìš°ëŒ€ì¡°ê±´'):
                            print(f"    ğŸ¯ ìš°ëŒ€ì¡°ê±´ {len(detail_info['ìš°ëŒ€ì¡°ê±´'])}ê°œ ìˆ˜ì§‘")
                        else:
                            print(f"    ğŸ“ ìš°ëŒ€ì¡°ê±´: ì—†ìŒ")
                    else:
                        print(f"    âŒ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")
                
                print(f"âœ… {category_name} í˜ì´ì§€ {page_num} ì™„ë£Œ: {len(new_products)}ê°œ ì‹ ê·œ ìƒí’ˆ")
                time.sleep(2)  # í˜ì´ì§€ ê°„ ëŒ€ê¸°
                
            except Exception as e:
                print(f"âŒ {category_name} í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        return category_products

    def navigate_to_page(self, category_name, base_url, page_num):
        """í˜ì´ì§€ë„¤ì´ì…˜ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • í˜ì´ì§€ë¡œ ì´ë™"""
        try:
            if page_num == 1:
                # ì²« í˜ì´ì§€ëŠ” ì§ì ‘ ì ‘ì†
                page_url = self.base_url + base_url
                print(f"ğŸŒ ì²« í˜ì´ì§€ ì ‘ì†: {page_url}")
                self.driver.get(page_url)
                time.sleep(3)
                return True
            
            # 2í˜ì´ì§€ ì´ìƒì¼ ê²½ìš° í˜ì´ì§€ë„¤ì´ì…˜ ë²„íŠ¼ í´ë¦­
            print(f"ğŸ” í˜ì´ì§€ {page_num} ë²„íŠ¼ ì°¾ëŠ” ì¤‘...")
            
            # í˜ì´ì§€ë„¤ì´ì…˜ ë²„íŠ¼ ì°¾ê¸°
            pagination_selectors = [
                f"//a[text()='{page_num}']",
                f"//button[text()='{page_num}']",
                f"//span[text()='{page_num}']/parent::a",
                f"//li/a[text()='{page_num}']",
                f"//*[contains(@class, 'page') and text()='{page_num}']",
            ]
            
            page_button = None
            
            for i, selector in enumerate(pagination_selectors, 1):
                try:
                    elements = self.driver.find_elements(By.XPATH, selector)
                    
                    for element in elements:
                        if element.is_displayed() and element.is_enabled():
                            page_button = element
                            print(f"      âœ… í˜ì´ì§€ {page_num} ë²„íŠ¼ ë°œê²¬!")
                            break
                    
                    if page_button:
                        break
                        
                except Exception as e:
                    continue
            
            # í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° JavaScriptë¡œ í˜ì´ì§€ ì´ë™ ì‹œë„
            if not page_button:
                print(f"      ğŸ” JavaScript í˜ì´ì§€ ì´ë™ ì‹œë„...")
                
                js_functions = [
                    f"goPage({page_num})",
                    f"movePage({page_num})",
                    f"pageMove({page_num})",
                    f"fn_goPage({page_num})",
                ]
                
                for js_func in js_functions:
                    try:
                        self.driver.execute_script(js_func)
                        time.sleep(3)
                        
                        if self.verify_page_change(page_num):
                            print(f"      âœ… JavaScriptë¡œ í˜ì´ì§€ {page_num} ì´ë™ ì„±ê³µ!")
                            return True
                            
                    except Exception as e:
                        continue
                
                print(f"      âŒ í˜ì´ì§€ {page_num} ì´ë™ ì‹¤íŒ¨")
                return False
            
            # í˜ì´ì§€ ë²„íŠ¼ í´ë¦­
            try:
                print(f"      ğŸ–±ï¸ í˜ì´ì§€ {page_num} ë²„íŠ¼ í´ë¦­...")
                page_button.click()
                time.sleep(3)
                
                if self.verify_page_change(page_num):
                    print(f"      âœ… í˜ì´ì§€ {page_num} ì´ë™ ì„±ê³µ!")
                    return True
                else:
                    print(f"      âŒ í˜ì´ì§€ {page_num} ì´ë™ ì‹¤íŒ¨")
                    return False
                
            except Exception as e:
                print(f"      âŒ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­ ì˜¤ë¥˜: {e}")
                return False
                
        except Exception as e:
            print(f"âŒ í˜ì´ì§€ {page_num} ì´ë™ ì „ì²´ ì˜¤ë¥˜: {e}")
            return False

    def verify_page_change(self, expected_page):
        """í˜ì´ì§€ ë³€ê²½ í™•ì¸"""
        try:
            time.sleep(2)
            
            # í˜„ì¬ ìƒí’ˆ ëª©ë¡ í™•ì¸
            try:
                products = self.driver.find_elements(By.CSS_SELECTOR, "a.stit")
                if len(products) > 0:
                    first_product = products[0].get_attribute('textContent').strip()
                    if hasattr(self, 'last_first_product'):
                        if first_product != self.last_first_product:
                            print(f"      âœ… ìƒí’ˆ ëª©ë¡ ë³€í™” í™•ì¸: '{first_product}'")
                            self.last_first_product = first_product
                            return True
                        else:
                            print(f"      âš ï¸ ë™ì¼í•œ ì²« ìƒí’ˆ: '{first_product}'")
                            return False
                    else:
                        self.last_first_product = first_product
                        return True
            except:
                pass
            
            return True
            
        except Exception as e:
            print(f"      âŒ í˜ì´ì§€ ë³€ê²½ í™•ì¸ ì˜¤ë¥˜: {e}")
            return True

    def extract_products_from_current_page(self):
        """í˜„ì¬ í˜ì´ì§€ì—ì„œ ìƒí’ˆ ëª©ë¡ ì¶”ì¶œ"""
        try:
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            products = []
            
            # ìƒí’ˆ ë§í¬ ì°¾ê¸°
            product_links = soup.find_all('a', class_='stit')
            
            for link in product_links:
                product_name = link.get_text(strip=True)
                onclick = link.get('onclick', '')
                
                if product_name and 'uf_showDetail' in onclick:
                    params = self.parse_onclick_params(onclick)
                    if params:
                        products.append({
                            'name': product_name,
                            'params': params
                        })
            
            return products
            
        except Exception as e:
            print(f"âŒ ìƒí’ˆ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []

    def parse_onclick_params(self, onclick_str):
        """onclickì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ"""
        pattern = r"uf_showDetail\s*\(\s*'([^']*)',\s*'([^']*)',\s*'([^']*)',\s*'([^']*)',\s*'([^']*)',\s*'([^']*)'\s*\)"
        match = re.search(pattern, onclick_str)
        
        if match:
            return {
                'param1': match.group(1),
                'param2': match.group(2),
                'param3': match.group(3),
                'param4': match.group(4),
                'param5': match.group(5),
                'param6': match.group(6)
            }
        return None

    def get_product_detail(self, product, category_name):
        """ìƒí’ˆ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘"""
        try:
            params = product['params']
            original_url = self.driver.current_url
            
            print(f"    ğŸ” ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
            
            # JavaScript ì‹¤í–‰í•˜ì—¬ ìƒì„¸ í˜ì´ì§€ ì ‘ì†
            script = f"""
            try {{
                uf_showDetail('{params['param1']}', '{params['param2']}', '{params['param3']}', 
                             '{params['param4']}', '{params['param5']}', '{params['param6']}');
                return true;
            }} catch(e) {{
                console.error('ìƒì„¸í˜ì´ì§€ ì˜¤ë¥˜:', e);
                return false;
            }}
            """
            
            js_result = self.driver.execute_script(script)
            
            if not js_result:
                print(f"    âŒ JavaScript ì‹¤í–‰ ì‹¤íŒ¨")
                return None
            
            # í˜ì´ì§€ ë³€í™” ëŒ€ê¸°
            time.sleep(4)
            
            # ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            detail_info = self.extract_detail_info(product['name'], category_name, original_url)
            
            # ì›ë˜ í˜ì´ì§€ë¡œ ë³µê·€
            self.return_to_original_page(original_url)
            
            return detail_info
                
        except Exception as e:
            print(f"    âŒ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)[:50]}...")
            return None

    def extract_detail_info(self, product_name, category_name, original_url):
        """ìƒì„¸ ì •ë³´ ì¶”ì¶œ (ê¸°ê°„ë³„ ê¸ˆë¦¬ í¬í•¨)"""
        try:
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            # ê¸°ë³¸ ì •ë³´ êµ¬ì„±
            product_info = {
                "ì€í–‰ëª…": "ê¸°ì—…ì€í–‰",
                "ìƒí’ˆëª…": product_name,
                "ìƒí’ˆìœ í˜•": category_name,
                "ìƒí’ˆìƒì„¸URL": self.driver.current_url,
                "í¬ë¡¤ë§ì¼ì‹œ": datetime.now().strftime("%Y-%m-%d")
            }
            
            # ê°€ì…ê¸ˆì•¡ ì¶”ì¶œ
            ê°€ì…ê¸ˆì•¡ = self.find_info_by_keywords(soup, ['ê°€ì…ê¸ˆì•¡', 'ê°€ì…í•œë„', 'ì˜ˆì¹˜ê¸ˆì•¡', 'ë‚©ì…ê¸ˆì•¡', 'ìµœì†Œê¸ˆì•¡', 'ìµœëŒ€ê¸ˆì•¡'])
            product_info['ê°€ì…ê¸ˆì•¡'] = ê°€ì…ê¸ˆì•¡ if ê°€ì…ê¸ˆì•¡ else "ì •ë³´ ì—†ìŒ"
            
            # ê°€ì…ëŒ€ìƒ ì¶”ì¶œ
            ê°€ì…ëŒ€ìƒ = self.find_info_by_keywords(soup, ['ê°€ì…ëŒ€ìƒ', 'ê°€ì…ìê²©', 'ê°€ì…ì¡°ê±´', 'ê³ ê°êµ¬ë¶„', 'ëŒ€ìƒê³ ê°'])
            product_info['ê°€ì…ëŒ€ìƒ'] = ê°€ì…ëŒ€ìƒ if ê°€ì…ëŒ€ìƒ else "ì •ë³´ ì—†ìŒ"
            
            # ê°€ì…ë°©ë²• ì¶”ì¶œ
            ê°€ì…ë°©ë²• = self.find_info_by_keywords(soup, ['ê°€ì…ë°©ë²•', 'ê°€ì…ê²½ë¡œ', 'ì‹ ì²­ë°©ë²•', 'ì ‘ìˆ˜ë°©ë²•', 'ê°€ì…ì±„ë„'])
            product_info['ê°€ì…ë°©ë²•'] = ê°€ì…ë°©ë²• if ê°€ì…ë°©ë²• else "ì •ë³´ ì—†ìŒ"
            
            # ê³„ì•½ê¸°ê°„ ì¶”ì¶œ
            ê³„ì•½ê¸°ê°„ = self.find_info_by_keywords(soup, ['ê³„ì•½ê¸°ê°„', 'ì˜ˆì¹˜ê¸°ê°„', 'ìƒí’ˆê¸°ê°„', 'ê³„ì•½ë§Œê¸°', 'ì˜ˆì¹˜ë§Œê¸°'])
            product_info['ê³„ì•½ê¸°ê°„'] = ê³„ì•½ê¸°ê°„ if ê³„ì•½ê¸°ê°„ else "ì •ë³´ ì—†ìŒ"
            
            # ê¸°ë³¸/ìµœëŒ€ ê¸ˆë¦¬ ì¶”ì¶œ
            ê¸°ë³¸ê¸ˆë¦¬, ìµœê³ ê¸ˆë¦¬ = self.extract_rates_correctly(soup)
            product_info['ê¸°ë³¸ê¸ˆë¦¬'] = ê¸°ë³¸ê¸ˆë¦¬
            product_info['ìµœëŒ€ê¸ˆë¦¬'] = ìµœê³ ê¸ˆë¦¬
            
            # ì„¸ì œí˜œíƒ ì¶”ì¶œ
            ì„¸ì œí˜œíƒ = self.find_info_by_keywords(soup, ['ì„¸ì œí˜œíƒ', 'ë¹„ê³¼ì„¸', 'ì„¸ê¸ˆìš°ëŒ€', 'ì†Œë“ê³µì œ', 'ì„¸ì•¡ê³µì œ'])
            product_info['ì„¸ì œí˜œíƒ'] = ì„¸ì œí˜œíƒ if ì„¸ì œí˜œíƒ and 'ì—†ìŒ' not in ì„¸ì œí˜œíƒ else None
            
            # ì˜ˆê¸ˆìë³´í˜¸ ì¶”ì¶œ
            ì˜ˆê¸ˆìë³´í˜¸ = self.find_info_by_keywords(soup, ['ì˜ˆê¸ˆìë³´í˜¸', 'ì˜ˆê¸ˆë³´í—˜', 'ë³´í˜¸í•œë„', 'ì˜ˆë³´'])
            product_info['ì˜ˆê¸ˆìë³´í˜¸'] = ì˜ˆê¸ˆìë³´í˜¸ if ì˜ˆê¸ˆìë³´í˜¸ else "5ì²œë§Œì› í•œë„ ë³´í˜¸"
            
            # ìš°ëŒ€ì¡°ê±´ ì¶”ì¶œ
            ìš°ëŒ€ì¡°ê±´ = self.extract_preferential_rates_fixed(soup)
            product_info['ìš°ëŒ€ì¡°ê±´'] = ìš°ëŒ€ì¡°ê±´
            
            # ê¸ˆë¦¬ê³„ì‚°ë°©ì‹ ì¶”ì¶œ
            ê¸ˆë¦¬ê³„ì‚°ë°©ì‹ = self.find_info_by_keywords(soup, ['ë³µë¦¬', 'ë‹¨ë¦¬', 'ê¸ˆë¦¬ê³„ì‚°', 'ì´ìê³„ì‚°'])
            if ê¸ˆë¦¬ê³„ì‚°ë°©ì‹:
                if 'ë³µë¦¬' in ê¸ˆë¦¬ê³„ì‚°ë°©ì‹:
                    product_info['ê¸ˆë¦¬ê³„ì‚°ë°©ì‹'] = "ë³µë¦¬"
                elif 'ë‹¨ë¦¬' in ê¸ˆë¦¬ê³„ì‚°ë°©ì‹:
                    product_info['ê¸ˆë¦¬ê³„ì‚°ë°©ì‹'] = "ë‹¨ë¦¬"
                else:
                    product_info['ê¸ˆë¦¬ê³„ì‚°ë°©ì‹'] = "ë³µë¦¬"  # ê¸°ë³¸ê°’
            else:
                product_info['ê¸ˆë¦¬ê³„ì‚°ë°©ì‹'] = "ë³µë¦¬"  # ê¸°ë³¸ê°’
            
            # ê¸°ê°„ë³„ ê¸ˆë¦¬ ì¶”ì¶œ (ìƒˆë¡œ ì¶”ê°€)
            ê¸°ê°„ë³„ê¸ˆë¦¬ = self.extract_period_rates_with_popup(soup)
            product_info['ê¸°ê°„ë³„ê¸ˆë¦¬'] = ê¸°ê°„ë³„ê¸ˆë¦¬
            
            return product_info
            
        except Exception as e:
            print(f"    âŒ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def extract_period_rates_with_popup(self, soup):
        """ê¸°ê°„ë³„ ê¸ˆë¦¬ ì¶”ì¶œ (íŒì—… ì²˜ë¦¬)"""
        try:
            # 1. ê¸ˆë¦¬ë³´ê¸° ë²„íŠ¼ ì°¾ê¸°
            rate_button = self.find_rate_button()
            
            if not rate_button:
                return None
            
            # 2. ê¸ˆë¦¬ë³´ê¸° ë²„íŠ¼ í´ë¦­
            try:
                self.driver.execute_script("arguments[0].click();", rate_button)
                time.sleep(3)
            except:
                return None
            
            # 3. ê¸°ê°„ë³„ ê¸ˆë¦¬ ì¶”ì¶œ
            period_rates = self.parse_period_rates_safe()
            
            # 4. íŒì—… ë‹«ê¸°
            self.close_rate_popup()
            
            return period_rates
            
        except Exception as e:
            return None

    def find_rate_button(self):
        """ê¸ˆë¦¬ë³´ê¸° ë²„íŠ¼ ì°¾ê¸°"""
        try:
            button_selectors = [
                "//button[contains(text(), 'ê¸ˆë¦¬ë³´ê¸°')]",
                "//a[contains(text(), 'ê¸ˆë¦¬ë³´ê¸°')]",
                "//span[contains(text(), 'ê¸ˆë¦¬ë³´ê¸°')]/parent::a",
                "//span[contains(text(), 'ê¸ˆë¦¬ë³´ê¸°')]/parent::button",
            ]
            
            for selector in button_selectors:
                try:
                    elements = self.driver.find_elements(By.XPATH, selector)
                    for element in elements:
                        if element.is_displayed():
                            return element
                except:
                    continue
            
            return None
            
        except Exception as e:
            return None

    def parse_period_rates_safe(self):
        """ì•ˆì „í•œ ê¸°ê°„ë³„ ê¸ˆë¦¬ íŒŒì‹± (ìœ„ì¹˜ ê¸°ë°˜ ì¤‘ë³µ ì œê±°)"""
        try:
            time.sleep(2)
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            period_rates = []
            
            # í˜ì´ì§€ ì „ì²´ í…ìŠ¤íŠ¸
            page_text = soup.get_text()
            
            # ë¨¼ì € ë²”ìœ„ íŒ¨í„´ë“¤ì„ ì°¾ì•„ì„œ í•´ë‹¹ ë¶€ë¶„ì„ ì œê±°í•œ í›„ ë‹¨ì¼ íŒ¨í„´ ê²€ìƒ‰
            used_positions = set()  # ì´ë¯¸ ì‚¬ìš©ëœ í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì¶”ì 
            
            # 1ë‹¨ê³„: ë²”ìœ„ íŒ¨í„´ë“¤ ë¨¼ì € ì²˜ë¦¬
            range_patterns = [
                ('1ê°œì›”ì´ìƒ 6ê°œì›”ë¯¸ë§Œ', r'1ê°œì›”ì´ìƒ\s*6ê°œì›”ë¯¸ë§Œ\s+(\d\.\d+)'),
                ('6ê°œì›”ì´ìƒ 12ê°œì›”ë¯¸ë§Œ', r'6ê°œì›”ì´ìƒ\s*12ê°œì›”ë¯¸ë§Œ\s+(\d\.\d+)'),
                ('12ê°œì›”ì´ìƒ 24ê°œì›”ë¯¸ë§Œ', r'12ê°œì›”ì´ìƒ\s*24ê°œì›”ë¯¸ë§Œ\s+(\d\.\d+)'),
                ('24ê°œì›”ì´ìƒ 36ê°œì›”ë¯¸ë§Œ', r'24ê°œì›”ì´ìƒ\s*36ê°œì›”ë¯¸ë§Œ\s+(\d\.\d+)'),
                ('36ê°œì›”ì´ˆê³¼ 60ê°œì›”ì´í•˜', r'36ê°œì›”ì´ˆê³¼\s*60ê°œì›”ì´í•˜\s+(\d\.\d+)'),
                
                # ë…„ ë²”ìœ„ë“¤
                ('1ë…„ì´ìƒ 2ë…„ë¯¸ë§Œ', r'1ë…„ì´ìƒ\s*2ë…„ë¯¸ë§Œ\s+(\d\.\d+)'),
                ('2ë…„ì´ìƒ 3ë…„ë¯¸ë§Œ', r'2ë…„ì´ìƒ\s*3ë…„ë¯¸ë§Œ\s+(\d\.\d+)'),
                ('3ë…„ì´ìƒ 4ë…„ë¯¸ë§Œ', r'3ë…„ì´ìƒ\s*4ë…„ë¯¸ë§Œ\s+(\d\.\d+)'),
                ('4ë…„ì´ìƒ 5ë…„ë¯¸ë§Œ', r'4ë…„ì´ìƒ\s*5ë…„ë¯¸ë§Œ\s+(\d\.\d+)'),
            ]
            
            # ë²”ìœ„ íŒ¨í„´ ì²˜ë¦¬ ë° ì‚¬ìš©ëœ ìœ„ì¹˜ ê¸°ë¡
            for period_name, pattern in range_patterns:
                try:
                    for match in re.finditer(pattern, page_text, re.IGNORECASE):
                        rate = float(match.group(1))
                        if 1.0 <= rate <= 5.0:
                            # ì¤‘ë³µ ì²´í¬
                            if not any(pr['ê¸°ê°„'] == period_name for pr in period_rates):
                                period_rates.append({
                                    'ê¸°ê°„': period_name,
                                    'ê¸ˆë¦¬': rate
                                })
                                
                                # ì‚¬ìš©ëœ ìœ„ì¹˜ ê¸°ë¡
                                used_positions.update(range(match.start(), match.end()))
                except Exception as regex_error:
                    continue
            
            # 2ë‹¨ê³„: ë‹¨ì¼ íŒ¨í„´ë“¤ ì²˜ë¦¬ (ì‚¬ìš©ëœ ìœ„ì¹˜ ì œì™¸)
            single_patterns = [
                ('12ê°œì›”', r'12ê°œì›”\s+(\d\.\d+)'),
                ('24ê°œì›”', r'24ê°œì›”\s+(\d\.\d+)'),
                ('36ê°œì›”', r'36ê°œì›”\s+(\d\.\d+)'),
                ('6ê°œì›”', r'6ê°œì›”\s+(\d\.\d+)'),
                ('18ê°œì›”', r'18ê°œì›”\s+(\d\.\d+)'),
                ('60ê°œì›”', r'60ê°œì›”\s+(\d\.\d+)'),
                
                # ë…„ ë‹¨ìœ„
                ('1ë…„', r'1ë…„\s+(\d\.\d+)'),
                ('2ë…„', r'2ë…„\s+(\d\.\d+)'),
                ('3ë…„', r'3ë…„\s+(\d\.\d+)'),
                ('4ë…„', r'4ë…„\s+(\d\.\d+)'),
                ('5ë…„', r'5ë…„\s+(\d\.\d+)'),
                
                # ê¸°íƒ€
                ('36ê°œì›”ì´í•˜', r'36ê°œì›”ì´í•˜\s+(\d\.\d+)'),
                ('12ê°œì›”ì´ìƒ', r'12ê°œì›”ì´ìƒ\s+(\d\.\d+)'),
            ]
            
            # ë‹¨ì¼ íŒ¨í„´ ì²˜ë¦¬ (ì‚¬ìš©ëœ ìœ„ì¹˜ì™€ ê²¹ì¹˜ì§€ ì•ŠëŠ” ê²ƒë§Œ)
            for period_name, pattern in single_patterns:
                try:
                    for match in re.finditer(pattern, page_text, re.IGNORECASE):
                        # ì´ë¯¸ ì‚¬ìš©ëœ ìœ„ì¹˜ì™€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
                        match_positions = set(range(match.start(), match.end()))
                        if not match_positions.intersection(used_positions):
                            rate = float(match.group(1))
                            if 1.0 <= rate <= 5.0:
                                # ì¤‘ë³µ ì²´í¬
                                if not any(pr['ê¸°ê°„'] == period_name for pr in period_rates):
                                    period_rates.append({
                                        'ê¸°ê°„': period_name,
                                        'ê¸ˆë¦¬': rate
                                    })
                                    
                                    # ì‚¬ìš©ëœ ìœ„ì¹˜ ê¸°ë¡
                                    used_positions.update(match_positions)
                except Exception as regex_error:
                    continue
            
            # 3ë‹¨ê³„: í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¶”ì¶œ (ë°±ì—…)
            if not period_rates:
                period_rates = self.extract_period_rates_from_tables(soup)
            
            return period_rates if period_rates else None
            
        except Exception as e:
            return None

    def extract_period_rates_from_tables(self, soup):
        """í…Œì´ë¸”ì—ì„œ ê¸°ê°„ë³„ ê¸ˆë¦¬ ì§ì ‘ ì¶”ì¶œ"""
        try:
            period_rates = []
            tables = soup.find_all('table')
            
            for table in tables:
                table_text = table.get_text()
                
                # ê¸ˆë¦¬ ê´€ë ¨ í…Œì´ë¸”ì¸ì§€ í™•ì¸
                if any(keyword in table_text for keyword in ['ì˜ˆê¸ˆì´ìœ¨í‘œ', 'ê¸ˆë¦¬êµ¬ë¶„', 'ì•½ì •ì´ìœ¨']):
                    rows = table.find_all('tr')
                    
                    for row in rows:
                        cells = row.find_all(['th', 'td'])
                        cell_texts = [cell.get_text(strip=True) for cell in cells]
                        
                        # ê° í–‰ì—ì„œ ê¸°ê°„ê³¼ ê¸ˆë¦¬ ì°¾ê¸°
                        if len(cell_texts) >= 2:
                            for i, cell in enumerate(cell_texts):
                                # ê¸°ê°„ì¸ì§€ í™•ì¸
                                if ('ê°œì›”' in cell or 'ë…„' in cell) and ('ì´ìƒ' in cell or 'ë¯¸ë§Œ' in cell or 'ì´í•˜' in cell or 'ì´ˆê³¼' in cell or cell.endswith('ê°œì›”') or cell.endswith('ë…„')):
                                    # ê°™ì€ í–‰ì—ì„œ ê¸ˆë¦¬ ì°¾ê¸°
                                    for j, other_cell in enumerate(cell_texts):
                                        if i != j:
                                            try:
                                                if '.' in other_cell and len(other_cell) <= 5:
                                                    rate_val = float(other_cell)
                                                    if 1.0 <= rate_val <= 5.0:
                                                        if not any(pr['ê¸°ê°„'] == cell for pr in period_rates):
                                                            period_rates.append({
                                                                'ê¸°ê°„': cell,
                                                                'ê¸ˆë¦¬': rate_val
                                                            })
                                            except:
                                                continue
                    
                    if period_rates:
                        break
            
            return period_rates
            
        except Exception as e:
            return []

    def close_rate_popup(self):
        """ê¸ˆë¦¬ íŒì—… ë‹«ê¸°"""
        try:
            # í™•ì¸ ë²„íŠ¼ ì°¾ê¸°
            close_buttons = self.driver.find_elements(By.XPATH, "//button[contains(text(), 'í™•ì¸')]")
            if close_buttons:
                close_buttons[0].click()
                time.sleep(1)
                return
            
            # ESC í‚¤
            from selenium.webdriver.common.keys import Keys
            self.driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.ESCAPE)
            time.sleep(1)
        except:
            pass

    def find_info_by_keywords(self, soup, keywords):
        """í‚¤ì›Œë“œë¡œ ì •ë³´ ì°¾ê¸°"""
        for keyword in keywords:
            # ë°©ë²• 1: í…Œì´ë¸” êµ¬ì¡° (th-td)
            th_elements = soup.find_all('th')
            for th in th_elements:
                if keyword in th.get_text():
                    tr = th.find_parent('tr')
                    if tr:
                        td = tr.find('td')
                        if td:
                            text = self.clean_text(td.get_text())
                            if text and len(text) > 3:
                                return text
            
            # ë°©ë²• 2: dt-dd êµ¬ì¡°
            dt_elements = soup.find_all('dt')
            for dt in dt_elements:
                if keyword in dt.get_text():
                    dd = dt.find_next_sibling('dd')
                    if dd:
                        text = self.clean_text(dd.get_text())
                        if text and len(text) > 3:
                            return text
            
            # ë°©ë²• 3: í…ìŠ¤íŠ¸ íŒ¨í„´
            page_text = soup.get_text()
            pattern = rf'{re.escape(keyword)}\s*[:ï¼š]\s*([^\n]{{10,150}})'
            match = re.search(pattern, page_text)
            if match:
                text = self.clean_text(match.group(1))
                if text:
                    return text
        
        return None

    def extract_rates_correctly(self, soup):
        """ê¸ˆë¦¬ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì¶”ì¶œ"""
        try:
            page_text = soup.get_text()
            
            # "ê¸°ë³¸ 2.85%" íŒ¨í„´ ì°¾ê¸°
            basic_pattern = r'ê¸°ë³¸\s*([0-9]\.[0-9]+)%'
            basic_match = re.search(basic_pattern, page_text)
            basic_rate = float(basic_match.group(1)) if basic_match else None
            
            # "ìµœê³  4.35" íŒ¨í„´ ì°¾ê¸°  
            max_patterns = [
                r'ìµœê³ \s*([0-9]\.[0-9]+)',
                r'ìµœëŒ€\s*([0-9]\.[0-9]+)%',
                r'ìµœê³ ê¸ˆë¦¬\s*([0-9]\.[0-9]+)%'
            ]
            
            max_rate = None
            for pattern in max_patterns:
                match = re.search(pattern, page_text)
                if match:
                    max_rate = float(match.group(1))
                    break
            
            return basic_rate, max_rate
            
        except Exception as e:
            return None, None

    def extract_preferential_rates_fixed(self, soup):
        """ìš°ëŒ€ì¡°ê±´ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œ"""
        try:
            conditions = []
            
            # ì „ì²´ í˜ì´ì§€ í…ìŠ¤íŠ¸ í™•ì¸
            page_text = soup.get_text()
            has_preferential = any(keyword in page_text for keyword in ['ìš°ëŒ€ê¸ˆë¦¬', 'ìš°ëŒ€ì¡°ê±´', '%p'])
            
            if not has_preferential:
                return None
            
            # 1. ì „ì²´ HTMLì—ì„œ ìš°ëŒ€ê¸ˆë¦¬ ê´€ë ¨ ì„¹ì…˜ë“¤ ëª¨ë‘ ì°¾ê¸°
            preferential_sections = self.find_all_preferential_sections(soup)
            
            for i, section in enumerate(preferential_sections, 1):
                # ê° ì„¹ì…˜ì—ì„œ ìš°ëŒ€ì¡°ê±´ ì¶”ì¶œ
                section_conditions = self.extract_conditions_from_section(section)
                if section_conditions:
                    for condition in section_conditions:
                        # ì¤‘ë³µ ë°©ì§€
                        condition_key = (condition['ì¡°ê±´'], condition['ì¶”ê°€ê¸ˆë¦¬'])
                        if not any((c['ì¡°ê±´'], c['ì¶”ê°€ê¸ˆë¦¬']) == condition_key for c in conditions):
                            conditions.append(condition)
            
            # 2. ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ íŒ¨í„´ ë§¤ì¹­ (ë³´ì¡° ë°©ë²•)
            if not conditions:
                text_conditions = self.extract_from_full_text(page_text)
                if text_conditions:
                    conditions.extend(text_conditions)
            
            return conditions if conditions else None
            
        except Exception as e:
            return None

    def find_all_preferential_sections(self, soup):
        """ìš°ëŒ€ê¸ˆë¦¬ ê´€ë ¨ ì„¹ì…˜ë“¤ ëª¨ë‘ ì°¾ê¸°"""
        try:
            sections = []
            
            # 1. í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
            tables = soup.find_all('table')
            for table in tables:
                table_text = table.get_text()
                if any(keyword in table_text for keyword in ['ìš°ëŒ€ê¸ˆë¦¬', 'ìš°ëŒ€ì¡°ê±´', 'ì¶”ê°€ê¸ˆë¦¬']):
                    if re.search(r'[0-9]\.[0-9]+%?p?', table_text):
                        sections.append(table)
            
            # 2. div, section ë“±ì—ì„œ ì°¾ê¸°
            for tag in ['div', 'section', 'td', 'th', 'p']:
                elements = soup.find_all(tag)
                for element in elements:
                    element_text = element.get_text()
                    if len(element_text) > 20:
                        if any(keyword in element_text for keyword in ['ìš°ëŒ€ê¸ˆë¦¬', 'ìš°ëŒ€ì¡°ê±´']):
                            if re.search(r'[0-9]\.[0-9]+%?p?', element_text):
                                # ì´ë¯¸ í¬í•¨ëœ ìƒìœ„ ìš”ì†Œê°€ ìˆëŠ”ì§€ í™•ì¸
                                is_duplicate = False
                                for existing_section in sections:
                                    if existing_section in element.parents or element in existing_section.parents:
                                        is_duplicate = True
                                        break
                                
                                if not is_duplicate:
                                    sections.append(element)
            
            return sections
            
        except:
            return []

    def extract_conditions_from_section(self, section):
        """íŠ¹ì • ì„¹ì…˜ì—ì„œ ìš°ëŒ€ì¡°ê±´ ì¶”ì¶œ"""
        try:
            conditions = []
            section_text = section.get_text()
            
            # 1. ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ì¡°ê±´ë“¤ ì°¾ê¸°
            numbered_conditions = self.extract_numbered_conditions(section_text)
            if numbered_conditions:
                conditions.extend(numbered_conditions)
            
            # 2. í…Œì´ë¸” êµ¬ì¡°ì—ì„œ ì°¾ê¸°
            if section.name == 'table':
                table_conditions = self.extract_from_table_rows(section)
                if table_conditions:
                    # ì¤‘ë³µ ì œê±°
                    existing_keys = {(c['ì¡°ê±´'], c['ì¶”ê°€ê¸ˆë¦¬']) for c in conditions}
                    for condition in table_conditions:
                        condition_key = (condition['ì¡°ê±´'], condition['ì¶”ê°€ê¸ˆë¦¬'])
                        if condition_key not in existing_keys:
                            conditions.append(condition)
            
            # 3. ì¼ë°˜ í…ìŠ¤íŠ¸ íŒ¨í„´ ë§¤ì¹­
            if not conditions:
                text_conditions = self.extract_from_text_patterns(section_text)
                if text_conditions:
                    conditions.extend(text_conditions)
            
            return conditions
            
        except:
            return []

    def extract_numbered_conditions(self, text):
        """ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ìš°ëŒ€ì¡°ê±´ ì¶”ì¶œ"""
        try:
            conditions = []
            
            # ë‹¤ì–‘í•œ ë²ˆí˜¸ í˜•íƒœì˜ íŒ¨í„´ë“¤
            number_patterns = [
                r'[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]',
                r'\([1-9]\)',
                r'[1-9]\.',
                r'[1-9]\)',
            ]
            
            # ê° ë²ˆí˜¸ íŒ¨í„´ë³„ë¡œ ìš°ëŒ€ì¡°ê±´ ì°¾ê¸°
            for pattern in number_patterns:
                numbered_sections = re.split(f'({pattern})', text)
                
                if len(numbered_sections) > 2:
                    for i in range(1, len(numbered_sections), 2):
                        if i + 1 < len(numbered_sections):
                            number = numbered_sections[i].strip()
                            content = numbered_sections[i + 1].strip()
                            
                            # í•´ë‹¹ ì„¹ì…˜ì—ì„œ ìš°ëŒ€ì¡°ê±´ê³¼ ê¸ˆë¦¬ ì¶”ì¶œ
                            condition_info = self.parse_numbered_condition(number, content)
                            if condition_info:
                                conditions.append(condition_info)
                    
                    break
            
            return conditions
            
        except Exception as e:
            return []

    def parse_numbered_condition(self, number, content):
        """ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ê° ì¡°ê±´ íŒŒì‹±"""
        try:
            # ê¸ˆë¦¬ íŒ¨í„´ ì°¾ê¸°
            rate_patterns = [
                r'ìµœê³ \s*ì—°\s*([0-9]\.[0-9]+)%p',
                r'ì—°\s*([0-9]\.[0-9]+)%p',
                r'([0-9]\.[0-9]+)%p',
            ]
            
            rate_value = None
            for pattern in rate_patterns:
                match = re.search(pattern, content)
                if match:
                    rate_value = float(match.group(1))
                    break
            
            if not rate_value:
                return None
            
            # ì¡°ê±´ëª… ì¶”ì¶œ
            condition_name = self.extract_condition_name_from_content(content)
            
            if condition_name:
                return {
                    "ì¡°ê±´": condition_name,
                    "ì¶”ê°€ê¸ˆë¦¬": rate_value
                }
            
            return None
            
        except:
            return None

    def extract_condition_name_from_content(self, content):
        """ì¡°ê±´ ë‚´ìš©ì—ì„œ ì¡°ê±´ëª… ì¶”ì¶œ"""
        try:
            # ì¡°ê±´ëª… íŒ¨í„´ë“¤
            condition_patterns = [
                (r'ê°€ì…ì‹œì .*?ë³µë¬´ê¸°ê°„.*?ìš°ëŒ€ê¸ˆë¦¬', 'ë³µë¬´ê¸°ê°„ë³„ ìš°ëŒ€ê¸ˆë¦¬'),
                (r'êµ°\s*ê¸‰ì—¬ì´ì²´.*?ìš°ëŒ€ê¸ˆë¦¬', 'êµ° ê¸‰ì—¬ì´ì²´'),
                (r'ì‹ ìš©.*?ì²´í¬ì¹´ë“œ.*?ì´ìš©.*?ìš°ëŒ€ê¸ˆë¦¬', 'ì‹ ìš©ì²´í¬ì¹´ë“œ ì´ìš©'),
                (r'ê¸‰ì—¬ì´ì²´.*?ìš°ëŒ€ê¸ˆë¦¬', 'ê¸‰ì—¬ì´ì²´'),
                (r'ìë™ì´ì²´.*?ìš°ëŒ€ê¸ˆë¦¬', 'ìë™ì´ì²´'),
                (r'ì¹´ë“œ.*?ì´ìš©.*?ìš°ëŒ€ê¸ˆë¦¬', 'ì¹´ë“œì´ìš©'),
                (r'ë³µë¬´ë‹¬ì„±.*?ì¶•í•˜ê¸ˆë¦¬', 'ë³µë¬´ë‹¬ì„± ì¶•í•˜ê¸ˆë¦¬'),
                (r'ìµœì´ˆ.*?ê±°ë˜.*?ìš°ëŒ€ê¸ˆë¦¬', 'ìµœì´ˆê±°ë˜'),
                (r'ê¸‰ì—¬ì´ì²´', 'ê¸‰ì—¬ì´ì²´'),
                (r'ìë™ì´ì²´', 'ìë™ì´ì²´'),
                (r'ì¹´ë“œ.*?ì´ìš©', 'ì¹´ë“œì´ìš©'),
                (r'ë³µë¬´ê¸°ê°„', 'ë³µë¬´ê¸°ê°„ë³„'),
                (r'êµ°.*?ê¸‰ì—¬', 'êµ° ê¸‰ì—¬ì´ì²´'),
                (r'ì²´í¬ì¹´ë“œ', 'ì²´í¬ì¹´ë“œ ì´ìš©'),
                (r'ë³µë¬´ë‹¬ì„±', 'ë³µë¬´ë‹¬ì„± ì¶•í•˜ê¸ˆë¦¬'),
                (r'ìµœì´ˆ.*?ê±°ë˜', 'ìµœì´ˆê±°ë˜ê³ ê° ìš°ëŒ€ê¸ˆë¦¬'),
            ]
            
            for pattern, condition_name in condition_patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    return condition_name
            
            # íŒ¨í„´ì— ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë“¤ ì¶”ì¶œ
            words = content.split()
            meaningful_words = []
            for word in words[:5]:
                cleaned_word = re.sub(r'[^\wê°€-í£]', '', word)
                if len(cleaned_word) > 1 and 'ìš°ëŒ€' not in cleaned_word and 'ê¸ˆë¦¬' not in cleaned_word:
                    meaningful_words.append(cleaned_word)
                    if len(meaningful_words) >= 2:
                        break
            
            if meaningful_words:
                return ' '.join(meaningful_words)[:15]
            
            return None
            
        except:
            return None

    def extract_from_table_rows(self, table):
        """í…Œì´ë¸” í–‰ì—ì„œ ìš°ëŒ€ì¡°ê±´ ì¶”ì¶œ"""
        try:
            conditions = []
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                
                if len(cells) >= 2:
                    for i in range(len(cells) - 1):
                        condition_text = self.clean_text(cells[i].get_text())
                        rate_text = self.clean_text(cells[i + 1].get_text())
                        
                        if condition_text and rate_text:
                            rate_match = re.search(r'([0-9]\.[0-9]+)%?p?', rate_text)
                            
                            if rate_match and self.is_meaningful_condition(condition_text):
                                clean_condition = self.clean_condition_name(condition_text)
                                
                                if clean_condition:
                                    rate_value = float(rate_match.group(1))
                                    conditions.append({
                                        "ì¡°ê±´": clean_condition,
                                        "ì¶”ê°€ê¸ˆë¦¬": rate_value
                                    })
            
            return conditions
            
        except:
            return []

    def extract_from_text_patterns(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ íŒ¨í„´ ë§¤ì¹­"""
        try:
            conditions = []
            
            patterns = [
                (r'ë³µë¬´ë‹¬ì„±.*?ì¶•í•˜ê¸ˆë¦¬[^0-9]*?ì—°\s*([0-9]\.[0-9]+)%p', "ë³µë¬´ë‹¬ì„± ì¶•í•˜ê¸ˆë¦¬"),
                (r'ìµœì´ˆ.*?ê±°ë˜.*?ê³ ê°.*?ìš°ëŒ€ê¸ˆë¦¬[^0-9]*?ì—°\s*([0-9]\.[0-9]+)%p', "ìµœì´ˆê±°ë˜ê³ ê° ìš°ëŒ€ê¸ˆë¦¬"),
                (r'ê¸‰ì—¬ì´ì²´.*?ìš°ëŒ€ê¸ˆë¦¬[^0-9]*?ì—°\s*([0-9]\.[0-9]+)%p', "ê¸‰ì—¬ì´ì²´"),
                (r'ìë™ì´ì²´.*?ìš°ëŒ€ê¸ˆë¦¬[^0-9]*?ì—°\s*([0-9]\.[0-9]+)%p', "ìë™ì´ì²´"),
                (r'ì¹´ë“œ.*?ì´ìš©.*?ìš°ëŒ€ê¸ˆë¦¬[^0-9]*?ì—°\s*([0-9]\.[0-9]+)%p', "ì¹´ë“œì´ìš©"),
                (r'êµ°\s*ê¸‰ì—¬ì´ì²´.*?ìš°ëŒ€ê¸ˆë¦¬[^0-9]*?ì—°\s*([0-9]\.[0-9]+)%p', "êµ° ê¸‰ì—¬ì´ì²´"),
                (r'ë³µë¬´ê¸°ê°„.*?ìš°ëŒ€ê¸ˆë¦¬[^0-9]*?ìµœê³ .*?ì—°\s*([0-9]\.[0-9]+)%p', "ë³µë¬´ê¸°ê°„ë³„ ìš°ëŒ€ê¸ˆë¦¬"),
                (r'ì‹ ìš©.*?ì²´í¬ì¹´ë“œ.*?ìš°ëŒ€ê¸ˆë¦¬[^0-9]*?ì—°\s*([0-9]\.[0-9]+)%p', "ì‹ ìš©ì²´í¬ì¹´ë“œ ì´ìš©"),
            ]
            
            for pattern, default_name in patterns:
                matches = re.finditer(pattern, text, re.IGNORECASE)
                for match in matches:
                    rate_value = float(match.group(1))
                    
                    match_start = max(0, match.start() - 50)
                    context = text[match_start:match.end()]
                    condition_name = self.extract_condition_from_context(context) or default_name
                    
                    conditions.append({
                        "ì¡°ê±´": condition_name,
                        "ì¶”ê°€ê¸ˆë¦¬": rate_value
                    })
            
            return conditions
            
        except:
            return []

    def extract_from_full_text(self, text):
        """ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ìš°ëŒ€ì¡°ê±´ ì¶”ì¶œ"""
        try:
            conditions = []
            
            sentences = re.split(r'[.!?]', text)
            
            for sentence in sentences:
                if '%p' in sentence and any(keyword in sentence for keyword in ['ìš°ëŒ€', 'ì¶•í•˜', 'ì¶”ê°€']):
                    rate_matches = re.findall(r'([0-9]\.[0-9]+)%p', sentence)
                    
                    for rate_str in rate_matches:
                        rate_value = float(rate_str)
                        
                        condition_name = self.extract_condition_from_sentence(sentence)
                        if condition_name:
                            conditions.append({
                                "ì¡°ê±´": condition_name,
                                "ì¶”ê°€ê¸ˆë¦¬": rate_value
                            })
            
            return conditions
            
        except:
            return []

    def extract_condition_from_context(self, context):
        """ë¬¸ë§¥ì—ì„œ ì¡°ê±´ëª… ì¶”ì¶œ"""
        condition_keywords = {
            'ë³µë¬´ë‹¬ì„±': 'ë³µë¬´ë‹¬ì„± ì¶•í•˜ê¸ˆë¦¬',
            'ìµœì´ˆ': 'ìµœì´ˆê±°ë˜ê³ ê° ìš°ëŒ€ê¸ˆë¦¬', 
            'ê¸‰ì—¬ì´ì²´': 'ê¸‰ì—¬ì´ì²´',
            'ìë™ì´ì²´': 'ìë™ì´ì²´',
            'ì¹´ë“œ': 'ì¹´ë“œì´ìš©',
            'ë³µë¬´ê¸°ê°„': 'ë³µë¬´ê¸°ê°„ë³„ ìš°ëŒ€ê¸ˆë¦¬'
        }
        
        for keyword, condition_name in condition_keywords.items():
            if keyword in context:
                return condition_name
        
        return None

    def extract_condition_from_sentence(self, sentence):
        """ë¬¸ì¥ì—ì„œ ì¡°ê±´ëª… ì¶”ì¶œ"""
        if 'ë³µë¬´ë‹¬ì„±' in sentence:
            return 'ë³µë¬´ë‹¬ì„± ì¶•í•˜ê¸ˆë¦¬'
        elif 'ìµœì´ˆ' in sentence and 'ê±°ë˜' in sentence:
            return 'ìµœì´ˆê±°ë˜ê³ ê° ìš°ëŒ€ê¸ˆë¦¬'
        elif 'ê¸‰ì—¬ì´ì²´' in sentence:
            return 'ê¸‰ì—¬ì´ì²´'
        elif 'ìë™ì´ì²´' in sentence:
            return 'ìë™ì´ì²´'
        elif 'ì¹´ë“œ' in sentence:
            return 'ì¹´ë“œì´ìš©'
        elif 'ë³µë¬´ê¸°ê°„' in sentence:
            return 'ë³µë¬´ê¸°ê°„ë³„ ìš°ëŒ€ê¸ˆë¦¬'
        else:
            return 'ìš°ëŒ€ê¸ˆë¦¬'

    def is_meaningful_condition(self, text):
        """ì˜ë¯¸ìˆëŠ” ì¡°ê±´ì¸ì§€ í™•ì¸"""
        if not text or len(text.strip()) < 2:
            return False
        
        meaningless = ['êµ¬ë¶„', 'ê¸ˆë¦¬', '%', 'ì—°', 'ìš°ëŒ€ì¡°ê±´', 'ìµœê³ ', 'í•©ê³„', 'ì´']
        if text.strip() in meaningless:
            return False
        
        meaningful_keywords = [
            'ë³µë¬´', 'ë‹¬ì„±', 'ì¶•í•˜', 'ìµœì´ˆ', 'ê±°ë˜', 'ê¸‰ì—¬', 'ì´ì²´', 'ìë™', 
            'ì¹´ë“œ', 'ì´ìš©', 'ì‹ ìš©', 'ì²´í¬', 'êµ°', 'í€ë“œ', 'ë³´í—˜', 'ì¸í„°ë„·', 'ëª¨ë°”ì¼'
        ]
        
        return any(keyword in text for keyword in meaningful_keywords)

    def clean_condition_name(self, condition_text):
        """ì¡°ê±´ëª… ì •ë¦¬"""
        try:
            cleaned = condition_text.strip()
            
            patterns_to_clean = [
                (r'^\s*-\s*', ''),
                (r'\s*\([^)]*\)\s*', ''),
                (r'\s*\*.*', ''),
                (r'\s+', ' '),
            ]
            
            for pattern, replacement in patterns_to_clean:
                cleaned = re.sub(pattern, replacement, cleaned)
            
            cleaned = cleaned.strip()
            
            if len(cleaned) > 20:
                if 'ê¸‰ì—¬ì´ì²´' in cleaned:
                    return 'ê¸‰ì—¬ì´ì²´'
                elif 'ìë™ì´ì²´' in cleaned:
                    return 'ìë™ì´ì²´'
                elif 'ì¹´ë“œ' in cleaned:
                    return 'ì¹´ë“œì´ìš©'
                elif 'ìµœì´ˆ' in cleaned:
                    return 'ìµœì´ˆê±°ë˜'
                elif 'ì¬ì˜ˆì¹˜' in cleaned:
                    return 'ì¬ì˜ˆì¹˜'
                else:
                    return cleaned[:15] + '...'
            
            return cleaned if len(cleaned) > 2 else None
            
        except:
            return condition_text.strip() if condition_text else None

    def return_to_original_page(self, original_url):
        """ì›ë˜ í˜ì´ì§€ë¡œ ì•ˆì „í•˜ê²Œ ë³µê·€"""
        try:
            current_url = self.driver.current_url
            
            if current_url != original_url:
                self.driver.back()
                time.sleep(2)
            
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "a.stit"))
            )
            
        except Exception as e:
            self.driver.get(original_url)
            time.sleep(3)

    def clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not text:
            return None
        
        text = re.sub(r'\s+', ' ', text.strip())
        
        if len(text) < 1:
            return None
        
        return text

    def save_results(self, results, filename=None):
        """ê²°ê³¼ ì €ì¥"""
        dotenv.load_dotenv()
        directory_path = os.getenv("JSON_RESULT_PATH")
        os.makedirs(directory_path, exist_ok=True)

        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"IBK.json"

        file_path = os.path.join(directory_path, filename)

        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {filename}")
            
            products = results.get('products', [])
            crawl_info = results.get('crawl_info', {})
            
            print(f"\nğŸ“Š === ìµœì¢… í¬ë¡¤ë§ í†µê³„ ===")
            print(f"í¬ë¡¤ë§ ì¼ì‹œ: {crawl_info.get('crawl_date', 'N/A')}")
            print(f"ì´ ìˆ˜ì§‘ ìƒí’ˆ: {len(products)}ê°œ")
            print(f"  â€¢ ì ê¸ˆ ìƒí’ˆ: {crawl_info.get('savings_count', 0)}ê°œ")
            print(f"  â€¢ ì˜ˆê¸ˆ ìƒí’ˆ: {crawl_info.get('deposits_count', 0)}ê°œ")
            print(f"ëª©í‘œ ëŒ€ë¹„: {len(products)}/{crawl_info.get('total_expected', 45)}ê°œ")
            
            products_with_conditions = [p for p in products if p.get('ìš°ëŒ€ì¡°ê±´')]
            products_with_period_rates = [p for p in products if p.get('ê¸°ê°„ë³„ê¸ˆë¦¬')]
            
            print(f"ìš°ëŒ€ì¡°ê±´ ë³´ìœ  ìƒí’ˆ: {len(products_with_conditions)}ê°œ")
            print(f"ê¸°ê°„ë³„ê¸ˆë¦¬ ë³´ìœ  ìƒí’ˆ: {len(products_with_period_rates)}ê°œ")
            
            if products:
                print(f"\nğŸ“‹ === ì²« 3ê°œ ìƒí’ˆ ìƒ˜í”Œ ===")
                for i, product in enumerate(products[:3], 1):
                    print(f"{i}. {product['ìƒí’ˆëª…']} ({product['ìƒí’ˆìœ í˜•']})")
                    print(f"   ê¸°ë³¸ê¸ˆë¦¬: {product.get('ê¸°ë³¸ê¸ˆë¦¬', 'N/A')}%, ìµœëŒ€ê¸ˆë¦¬: {product.get('ìµœëŒ€ê¸ˆë¦¬', 'N/A')}%")
                    print(f"   ê³„ì•½ê¸°ê°„: {product.get('ê³„ì•½ê¸°ê°„', 'N/A')}")
                    
                    if product.get('ê¸°ê°„ë³„ê¸ˆë¦¬'):
                        print(f"   ê¸°ê°„ë³„ê¸ˆë¦¬: {len(product['ê¸°ê°„ë³„ê¸ˆë¦¬'])}ê°œ")
                        for rate in product['ê¸°ê°„ë³„ê¸ˆë¦¬'][:2]:
                            print(f"     - {rate['ê¸°ê°„']}: {rate['ê¸ˆë¦¬']}%")
                    else:
                        print(f"   ê¸°ê°„ë³„ê¸ˆë¦¬: ì—†ìŒ")
                        
                    if product.get('ìš°ëŒ€ì¡°ê±´'):
                        print(f"   ìš°ëŒ€ì¡°ê±´: {len(product['ìš°ëŒ€ì¡°ê±´'])}ê°œ")
                        for condition in product['ìš°ëŒ€ì¡°ê±´'][:2]:
                            print(f"     - {condition['ì¡°ê±´']}: +{condition['ì¶”ê°€ê¸ˆë¦¬']}%p")
                    else:
                        print(f"   ìš°ëŒ€ì¡°ê±´: ì—†ìŒ")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def start(self):
        print("ğŸš€ ibk ì ê¸ˆ/ì˜ˆê¸ˆ ì „ì²´ í¬ë¡¤ëŸ¬ (ê¸°ê°„ë³„ ê¸ˆë¦¬ í¬í•¨)")
        print("ğŸ“‹ ëª©ëˆëª¨ìœ¼ê¸°(ì ê¸ˆ) 28ê°œ + ëª©ëˆêµ´ë¦¬ê¸°(ì˜ˆê¸ˆ) 17ê°œ = ì´ 45ê°œ ìƒí’ˆ")
        print("ğŸ¯ ê¸°ê°„ë³„ ê¸ˆë¦¬, ìš°ëŒ€ì¡°ê±´ ë“± ëª¨ë“  ì •ë³´ í¬í•¨ í¬ë¡¤ë§\n")

        try:
            results = self.crawl_all_products()

            if results and len(results.get('products', [])) > 0:
                success = self.save_results(results)

                if success:
                    print(f"\nğŸ‰ ì „ì²´ í¬ë¡¤ë§ ë° ì €ì¥ ì™„ë£Œ!")
                    print(f"ğŸ“„ JSON íŒŒì¼ì— {len(results['products'])}ê°œ ìƒí’ˆ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    print(f"ğŸ“Š ê¸°ê°„ë³„ ê¸ˆë¦¬ ì •ë³´ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            else:
                print("âŒ í¬ë¡¤ë§ ì‹¤íŒ¨ - ìˆ˜ì§‘ëœ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤")

        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤")
        except Exception as e:
            print(f"\nğŸ’¥ ì˜¤ë¥˜ ë°œìƒ: {e}")

